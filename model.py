# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LexHG9Qsm1pkqKoo8-BgZmQJSr_IDH_e

# Capstone Project - Product Recommendation System using Sentiment Analysis



# Problem Statement
The e-commerce business is quite popular today. Here, you do not need to take orders by going to each customer. A company launches its website to sell the items to the end consumer, and customers can order the products that they require from the same website. Famous examples of such e-commerce companies are Amazon, Flipkart, Myntra, Paytm and Snapdeal.



Suppose you are working as a Machine Learning Engineer in an e-commerce company named 'Ebuss'. Ebuss has captured a huge market share in many fields, and it sells the products in various categories such as household essentials, books, personal care products, medicines, cosmetic items, beauty products, electrical appliances, kitchen and dining products and health care products.



With the advancement in technology, it is imperative for Ebuss to grow quickly in the e-commerce market to become a major leader in the market because it has to compete with the likes of Amazon, Flipkart, etc., which are already market leaders.



As a senior ML Engineer, you are asked to build a model that will improve the recommendations given to the users given their past reviews and ratings.



In order to do this, you planned to build a sentiment-based product recommendation system, which includes the following tasks.

- Data sourcing and sentiment analysis
- Building a recommendation system
- Improving the recommendations using the sentiment analysis model
- Deploying the end-to-end project with a user interface

## Imports
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import time

import nltk
import ssl
from nltk.util import ngrams

try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

nltk.download('punkt')
nltk.download('stopwords')

from nltk.stem.porter import PorterStemmer
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords


from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn import metrics
from sklearn.metrics.pairwise import pairwise_distances
from sklearn.preprocessing import MinMaxScaler

# !pip install xgboost
import xgboost as xgb
# !pip install wordcloud
from wordcloud import WordCloud

import joblib

# function for printing columns with their percentage missing values
def print_missing_val_percent_in_cols(df):
    for col in df.columns:
        missing_percent = df[col].isnull().sum() / df.shape[0] * 100
        print('{}: {}'.format(col, round(missing_percent, 2)))

# function to return the columns with missing values
def find_missing_val_cols(df):
    missing_val_cols = []
    for col in df.columns:
        if df[col].isnull().sum() > 0:
            missing_val_cols.append(col)
    return missing_val_cols

# function to return columns of the dataframe containing string x
def get_cols(df, x):
    x_cols = []
    for col in df.columns:
        if x in col:
            x_cols.append(col)
    return x_cols

def get_data_missing_cols(df):
    data_missing_cols = []
    for col in df.columns:
        if df[col].isnull().sum() > 0:
            if 'num_of_days' not in col:
                data_missing_cols.append(col)
            print(col, round(df[col].isnull().sum() / len(df) * 100, 2))
    return data_missing_cols

def divide_columns_based_on_number_of_unique_values(df, num_unique_vals):
    col_large_unique = []
    col_small_unique = []
    for col in df:
        if len(df[col].unique()) > num_unique_vals:
            col_large_unique.append(col)
        else:
            col_small_unique.append(col)

    print(f'more than {num_unique_vals} unique values:\nlist: {col_large_unique} \ntotal columns: {len(col_large_unique)}')
    print()

    print(f'less than {num_unique_vals} unique values:\nlist: {col_small_unique} \ntotal columns: {len(col_small_unique)}')
    print()

    return col_large_unique, col_small_unique

def plot_small(df, column):
    '''Common plot function for columns with small number of unique values'''
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))
    sns.countplot(x = column, data=df, ax=ax1)
    df[column].value_counts().plot(kind='pie', ax=ax2, autopct='%1.1f%%')
    plt.suptitle(f"{column} [dtype: {df[column].dtype}]")
    plt.savefig(f"{column}.png")
    plt.show()

    print(df[column].value_counts().to_string())

def plot_large(df, column):
    '''Common plot function for columns with large number of unique values'''
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18,5))
    plt.suptitle(f"{column} [dtype: {df[column].dtype}]")
    try:
        sns.histplot(df[column], bins=50, ax=ax1)
        ax1.set_xticks(ax1.get_xticklabels(), rotation=90)
    except:
        pass
    try:
        sns.kdeplot(x=column, data=df, ax=ax2)
    except:
        pass
    try:
        sns.boxplot(x=column, data=df, ax=ax3)
    except:
        pass
    # plt.savefig(f"{column}.png")
    plt.show()
    print(df[column].describe().to_string())
    print()


# function to generate all the concerned evaluation metrics for a model
model_scores_dict = {}
def classification_metrics(y_actual, y_pred, model_name_key=None):

    confusion_mat = metrics.confusion_matrix(y_actual, y_pred)
    TP = confusion_mat[1,1] # true positive
    TN = confusion_mat[0,0] # true negatives
    FP = confusion_mat[0,1] # false positives
    FN = confusion_mat[1,0] # false negatives

    sensitivity = TP/(TP+FN)
    specificity = TN/(TN+FP)
    accuracy = metrics.accuracy_score(y_actual, y_pred)
    precision = metrics.precision_score(y_actual, y_pred)
    recall = metrics.recall_score(y_actual, y_pred)
    TPR = sensitivity
    FNR = FN/(TP+FN)
    FPR = FP/(FP+TN)
    f1 = metrics.f1_score(y_actual, y_pred)

    clf_data = [[sensitivity, specificity, accuracy, precision, recall, TPR, FNR, FPR, f1]]
    clf_df = pd.DataFrame(clf_data, columns=['sensitivity', 'specificity', 'accuracy', 'precision', 'recall', 'TPR', 'FNR', 'FPR', 'F1_score'])
    clf_df = round(clf_df, 2)

    if model_name_key:
        model_scores_dict[model_name_key] = np.round(np.array(clf_data[0]),2)
    return clf_df

def draw_roc(actual, probs):
    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,
                                              drop_intermediate = False )
    auc_score = metrics.roc_auc_score( actual, probs )
    plt.figure(figsize=(5, 5))
    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver operating characteristic example')
    plt.legend(loc="lower right")
    plt.show()

    return None


# function to genarate Churn labels from the class probability for all the given thresholds
def generate_prob_threshold_df(y_actual, y_pred_prob, thresholds):

    y_pred_prob = y_pred_prob[:, 1]
    # thresholds = np.round(np.arange(0, 1, 0.1), 2)
    threshold_df = pd.DataFrame(list(zip(y_actual, y_pred_prob)), columns=['Actual Churn', 'Probability'])

    for i in thresholds:
        churn_pred = [1 if p >= i else 0 for p in y_pred_prob]
        threshold_df[i] = churn_pred

    return threshold_df

# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.
def generate_optimal_cutoff_df(threshold_df, thresholds):
    cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])

    for i in thresholds:
        cm1 = metrics.confusion_matrix(threshold_df['Actual Churn'], threshold_df[i])
        total1=sum(sum(cm1))
        accuracy = (cm1[0,0]+cm1[1,1])/total1

        speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])
        sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])
        cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]
    return cutoff_df

# function to find optimal cut off point
def metrics_on_different_thresholds(y_actual, thresholds, threshold_df):
    '''Helper function to find optimal cut off point by try various thresholds'''
    joined_df = pd.DataFrame(columns=['sensitivity', 'specificity', 'accuracy', 'precision', 'recall', 'TPR', 'FNR', 'FPR', 'F1_score'])
    for i in thresholds:
        joined_df = pd.concat([joined_df, classification_metrics(y_actual, threshold_df[i])])
    joined_df = joined_df.set_index(thresholds)
    return joined_df



from google.colab import drive
drive.mount('/content/drive')

"""## Loading Data"""

df = pd.read_csv('/content/drive/MyDrive/Colab/sample30.csv')

"""## EDA"""

df.head()

df.info()

df.isnull().sum()

df.reviews_didPurchase.value_counts()

df.shape

df.describe()

df['id'].value_counts()

df['brand'].value_counts()

df.nunique()

df['user_sentiment'].value_counts()

df.isnull().sum()

df[df['manufacturer'].isnull()].head()

"""## Null Value Analysis"""

df.isnull().mean().round(4).mul(100).sort_values(ascending=False)

df[df['reviews_username'].isnull()].head(2)

"""#### Decison
- Dropping the user province and user city columns as they have more than 90% values missing
- Dropping the "didPurchase" column for now as it has more than 50% data missing.
    - We can give more weightage to those reviews where the user actually purchased the product
    - However, that can be part of phase 2. especially due to missing value count being so high
"""

df.drop(['reviews_didPurchase', 'reviews_userProvince', 'reviews_userCity'], axis=1, inplace=True)

df.isnull().mean().round(4).mul(100).sort_values(ascending=False)

df[df['reviews_title'].isnull()].head()

df[~df['reviews_title'].isnull()].head()

df[df['id']=='AV16khLE-jtxr-f38VFn']

"""#### ID column doesn't seem to be off much use so dropping it
- Looks like it corresponds to the product names like a unique id for the product name. We'll use the 'product name' column instead as it would be more descriptive.
"""

df.drop('id', axis=1, inplace=True)

df.head(2)

df.loc[4]['reviews_text']

df.loc[4]

df.loc[20]['reviews_text']

df.tail(3)

df.loc[29997]['reviews_text']

df.loc[29998]['reviews_text']

df[df['reviews_text'].str.contains('This review was collected as part of a promotion')]

df.loc[41]['reviews_text']

df.shape

"""#### Missing Review Titles
- After taking a look at a couple of review texts and corresponding titles above, it seems that most titles just have some words from the review text itself or the title just compliments the text.

For further analysis, there are 2 approaches
1. drop review titles column
2. combine review titles and reviews text together into a single column

#### Decision
I'm inclined towards dropping the title column since it has redundant information
"""

df.drop('reviews_title', axis=1, inplace=True)

df.head(2)

df.isnull().sum()

df[df['user_sentiment'].isnull()]

df.loc[28354]['reviews_text']

df['reviews_username'].nunique()

df['reviews_username'].head()

df['reviews_username'].tail()

df[df['reviews_username']=='7.87E+11']

"""#### Note
- The above username is super strange (it's more like a number) but I will let it go for now.
- Further, it does seem like there are duplicate records, so I'll clean those up.

#### Removing Duplicates
"""

df[df.duplicated()].shape

df[df.duplicated(keep=False)].head(4)

df[df['reviews_username']=='mylifeinheels']

df.drop_duplicates(keep='first', inplace=True)

df.shape

"""##### Making sure we have kept one of the duplicates in above operation"""

df[df['reviews_username']=='mylifeinheels']

df.loc[67]['reviews_text']

df.loc[79]['reviews_text']

df.loc[67]['reviews_text'] == df.loc[79]['reviews_text']

"""#### Looks like there are duplicate reviews made on different times as well."""

df.duplicated(subset=['reviews_text', 'reviews_username', 'name']).sum()

df[df.duplicated(subset=['reviews_text', 'reviews_username', 'name', 'brand', 'categories', 'reviews_date'], keep=False)]

"""#### Observation
Sometimes, the same reviews have two values for reviews_doRecommend one of which is NaN.

#### Decision
In such a case, the row with NaN value should be dropped
"""

df[df.duplicated(subset=['reviews_text', 'reviews_username', 'name', 'brand', 'categories', 'reviews_date'], keep=False) & df['reviews_doRecommend'].isnull()]

df.drop(df[df.duplicated(subset=['reviews_text', 'reviews_username', 'name', 'brand', 'categories', 'reviews_date'], keep=False) & df['reviews_doRecommend'].isnull()].index, inplace=True)

df.loc[4150:4153]

df[df.duplicated(subset=['reviews_text', 'reviews_username', 'name', 'brand', 'categories', 'reviews_date'], keep=False)]

df.loc[18577].reviews_text

"""#### Observation
In the above case, it seems that the customer is unhappy due to the difference in prices

#### Decision
I'll keep the review with the lower ratings.
"""

df.drop(20483, inplace=True)

df[df.duplicated(subset=['reviews_text', 'reviews_username', 'name', 'brand', 'categories', 'reviews_date'], keep=False)]

df[df.duplicated(subset=['reviews_text', 'reviews_username', 'name', 'brand', 'categories', 'manufacturer'], keep=False)].shape

df[df.duplicated(subset=['reviews_text', 'reviews_username', 'name', 'brand', 'categories', 'manufacturer', 'reviews_doRecommend'], keep=False)].shape

df[df.duplicated(subset=['reviews_text', 'reviews_username', 'name', 'brand', 'categories', 'manufacturer', 'reviews_doRecommend', 'reviews_rating'], keep=False)].shape

"""#### Observation
It seems some users have changed their ratings and reviews_doRecommend flag after giving a review
"""

df[df.duplicated(subset=['reviews_text', 'reviews_username', 'name', 'brand', 'categories', 'manufacturer', 'reviews_doRecommend', 'reviews_rating'], keep=False)].shape

a = df[df.duplicated(subset=['reviews_text', 'reviews_username', 'name', 'brand', 'categories', 'manufacturer'], keep=False)]

a.shape

b = a.drop_duplicates(['reviews_text', 'reviews_username', 'name', 'reviews_doRecommend'], keep='last')

b.shape

b.duplicated(['reviews_text']).sum()

b[b.duplicated(['reviews_text'], keep=False)].head()

b[b.duplicated(['reviews_text'], keep=False) & b['reviews_doRecommend'].isnull()]

"""#### Observation
On anlayzing further, it seems that difference is again due to the "doRecommend" flag only.

#### Decision
We'll keep only those entries where value for "doRecommend" flag value is present among the duplicate entries
"""

df[
    df.duplicated(subset=['reviews_text', 'reviews_username', 'name'], keep=False) &
    df['reviews_doRecommend'].isnull()
  ].shape

df.drop(
    df[
        df.duplicated(subset=['reviews_text', 'reviews_username', 'name'], keep=False) &
        df['reviews_doRecommend'].isnull()
  ].index, inplace=True)

df.shape

df[df.duplicated(subset=['reviews_text', 'reviews_username', 'name', 'categories', 'reviews_doRecommend', 'user_sentiment', 'reviews_date'])].shape

"""### Observation

Only those duplicates remain where date is different.

### Decision

We'll keep only one of those entries.
"""

# df.dtypes

"""##### reviews_date column analysis
- converting column to date time
- checking missing value patterns
"""

df['reviews_date'] = df['reviews_date'].str.replace('\..+', '', regex=True)

df['reviews_date'].head()

df['reviews_date'].isnull().sum()

df['reviews_date'].value_counts()[0:5]

df[df['reviews_date'].isnull()]

df[df['name'] == 'Home Health Hairever Shampoo']

df[df['brand'] == 'Target.com Use Only']

"""#### Observation
No connection with respect to name or brand when date is missing. It could just be a random error.

#### Decision
Filling the value with mode for now. It shouldn't impact the analysis too much since the missing values are quite low in number
"""

df['reviews_date'].fillna(df['reviews_date'].mode()[0])

# pd.to_datetime(df['reviews_date'].fillna(df['reviews_date'].mode()[0]), format='%Y-%m-%dT%H:%M:%S')

df['reviews_date'] = df['reviews_date'].str.replace(" hooks slide or swivel into any desired position doesn't match format specified", df['reviews_date'].mode()[0])

# pd.to_datetime(df['reviews_date'].fillna(df['reviews_date'].mode()[0]), format='%Y-%m-%dT%H:%M:%S')

df['reviews_date'].fillna(df['reviews_date'].mode()[0], inplace=True)

df['reviews_date'].isnull().sum()

# df['reviews_date'] = pd.to_datetime(df['reviews_date'], format='%Y-%m-%dT%H:%M:%S', utc=True)

df.head(5)

df.dtypes

df.loc[28421]['name']

df[df['brand'] == 'Concept Housewares']

"""#### Observation
- All 'Concept Housewares' have an issue with the 'reviews_date' column
- Seems like some part of description of the product got mixed into the date column
- I'll replace these entries with the mode
"""

df.head()

df.isnull().sum()

df[df['user_sentiment'].isnull()]

df.loc[28354].reviews_text

"""#### Decision
Filling the missing sentiment with "positive" looking at the reviews text.
"""

df.loc[28354, 'user_sentiment'] = 'Positive'

df.isnull().sum()

df[df['manufacturer'].isnull()]['name'].value_counts()

df[df['manufacturer'].isnull()].head(2)

df[df['brand'] == 'Summit Entertainment']['manufacturer'].value_counts()

"""#### Observation
- The missing values for manufacturer are for the same product namely 'Alex Cross (dvdvideo)'
- The brand is 'Summit Entertainment'
- For all other products of 'Summit Entertainment', the manufacturer was 'Summit Entertainment'

#### Decision
- Fill the missing manufacturer with 'Summit Entertainment'
"""

df['manufacturer'].fillna('Summit Entertainment', inplace=True)

df.isnull().sum()

df[df['reviews_username'].isnull()].head(6)

"""#### dropping duplicate reviews made on different times"""

df.drop_duplicates(subset=['reviews_text', 'reviews_username', 'name'], inplace=True)

df.shape

df.isnull().sum()

df[df.duplicated(['reviews_text'])].shape

df[df.duplicated(['reviews_text', 'name'])].shape

df[df.duplicated(['reviews_text', 'name', 'reviews_rating', 'reviews_doRecommend'])].shape

df[df.duplicated(['reviews_text', 'name'], keep=False)].tail(10)

df[df.duplicated(['reviews_text', 'name', 'reviews_rating', 'reviews_doRecommend'], keep=False)]

df[df['reviews_username'] == 'mom and teacher']

df[df.duplicated(['reviews_text', 'name', 'reviews_rating', 'reviews_doRecommend'], keep=False)
   &
   df['reviews_doRecommend'].isnull()
  ]

"""#### Observation
Some reviews texts are duplicate and are given by the same person but there is a discrepancy in their name. One review has a user name with spaces while other has no spaces. ex: 'momandteacher' vs 'mom and teacher'

#### Decision
Create a new column with usernames without spaces and remove duplicates using that column
"""

df['reviews_username_no_spaces'] = df['reviews_username'].str.replace(' ', '')

df.shape

df[df.duplicated(['reviews_text', 'name', 'reviews_username_no_spaces'], keep=False)].shape

df.drop_duplicates(['reviews_text', 'name', 'reviews_username_no_spaces'], keep='first', inplace=True)

df.shape

df[df.duplicated(['reviews_text', 'name', 'reviews_rating', 'reviews_doRecommend'], keep=False)]

df[df['reviews_username'] == 'none']

df[df.duplicated(['reviews_text', 'name', 'reviews_rating', 'reviews_doRecommend'], keep=False)
  &
   df['reviews_username'].isnull()
  ]

df[df.duplicated(['reviews_text', 'name', 'reviews_rating', 'reviews_doRecommend'], keep=False)]['reviews_username'].value_counts()

df.isnull().sum()

"""#### Checking if dropping rows with username missing is a viable strategy"""

names_of_products_with_missing_username = list(set(df[df['reviews_username'].isnull()]['name'].to_list()))

names_of_products_with_missing_username

df[df['name'].isin(names_of_products_with_missing_username)]['name'].value_counts()

df[df['reviews_username'].isnull()]['name'].value_counts()

"""#### Dropping rows which have same data except for a missing username"""

df[df.duplicated(['reviews_text', 'name', 'reviews_rating', 'reviews_doRecommend'], keep=False)
  &
   df['reviews_username'].isnull()
  ]['reviews_text'].to_list()

df[df['reviews_text'] == 'The Axe Phoenix has a great smell to it but about 20 minutes after applying the scent starts to make you feel sick. Also the product is very clumpy and gritty once you put it on, leaving it hard to wash off in the shower. This is definitely still the little boys or teenagers deodorant. This review was collected as part of a promotion.']

df.drop(17760, inplace=True)

df[df['reviews_text'] == "I love this cookware. It's non-stick and made in Italy. Be sure to follow the seasoning directions before using and do not use on high heat. You'll be rewarded with easy cooking and cleanup."]

df.drop(18308, inplace=True)

df.shape

df.isnull().sum()

df[df['reviews_username'].isnull()]['name'].value_counts()

df[df['name'].isin(names_of_products_with_missing_username)]['name'].value_counts()

df.isnull().sum()

"""#### Decision
We can remove the rows with missing usernames as the count is low and products have reviews from other customers.
"""

df.drop('reviews_username_no_spaces', axis=1, inplace=True)

df.drop(df[df['reviews_username'].isnull()].index, inplace=True)

df.shape

"""### Finishing Null Value Analysis
- Removed duplicate entries by careful selection and bucketing
- Removed columns with too many missing values
- Impute missing values using business logic or statistical analysis depending on scenario.

---

### Anlayzing Sentiment and Ratings
"""

sns.countplot(x='user_sentiment', data=df, palette="GnBu")
plt.show()

df['reviews_rating'].describe()

df['reviews_rating'].value_counts()

sns.countplot(x='reviews_rating', data= df, palette="Greens")

"""### Observation
- There is high class imbalance in both ratings and sentiment favoring the poistive side.

### Decision
- During model building, we can use 'smote' to balance the datasets.
"""

df.head(2)

"""### Most common brands (Top 10)"""

df['brand'].value_counts()[:10].plot(kind='bar')
plt.show()

most_common_brands = df['brand'].value_counts()[:10].index.to_list()

most_common_brands_df = df[df['brand'].isin(most_common_brands)]

# most_common_brands_df.head()

"""#### Brands againts ratings"""

most_common_brands_df.pivot_table(
    index='brand',
    values='reviews_rating',
    aggfunc='mean'
).sort_values(by='reviews_rating', ascending=False)#.plot(kind='barh')

"""### Observation
- All top 10 brands have ratings above 4 stars
- Clorax has the highest ratings (4.82)

### Sentiment against Ratings
"""

df['user_sentiment'].value_counts()

pd.crosstab(index=df['reviews_rating'], columns=df['user_sentiment'])

df.pivot_table(
    index='user_sentiment',
    # columns='reviews_rating',
    values='reviews_rating'
)

"""#### Observation
The sentiment provided to us seems a bit off. The lower ratings should generally have negative sentiment associated with them.
"""

df.loc[
    (df['user_sentiment']=='Positive')
    &
    (df['reviews_rating']<3)
    ]['reviews_text'].to_list()[0:3]

df.loc[
    (df['user_sentiment']=='Negative')
    &
    (df['reviews_rating']<3)
    ]['reviews_text'].to_list()[0:3]

df.loc[
    (df['user_sentiment']=='Negative')
    &
    (df['reviews_rating']>3)
    ]['reviews_text'].to_list()[0:3]

"""### Decision
- We can remove 'This review was collected as part of a promotion.' from reviews_text. It does not provide any useful information for sentiment analysis
- We can apply a rating based rule to fix the sentiments of the reviews before building classification model.
"""

df['reviews_text'] = df['reviews_text'].str.replace('This review was collected as part of a promotion.', '', regex=False)

df.loc[
    (df['user_sentiment']=='Negative')
    &
    (df['reviews_rating']>3)
    ]['reviews_text'].to_list()[0:3]

# fixing sentiment. for rating==3, we are not updating existing sentiment.
df.loc[df['reviews_rating'] < 3, 'user_sentiment']='Negative'
df.loc[df['reviews_rating'] > 3, 'user_sentiment']='Positive'

pd.crosstab(index=df['reviews_rating'], columns=df['user_sentiment'])

df['name'].value_counts()[0:5]

#def count_sentiment(prod_name, inp_sent):
#    return df[(df['name']==prod_name) & (df['user_sentiment'] == inp_sent)].count()[0]

"""---

## Text Processing and EDA on Reviews

#### Checking blank reviews
"""

df['reviews_text'].isna().sum()

df[df['reviews_text'].str.strip() == ''].head()

"""## Approach
- using stemmer for fast processing
- removing stopwords
- removing punctuations
"""

stemmer = PorterStemmer()

# add stemming and lemmatisation in the preprocess function
def preprocess(document):
    'changes document to lower case and removes stopwords'

    # change sentence to lower case and strip characters
    document = document.lower().strip()

    # tokenize into words
    words = word_tokenize(document)

    # remove stop words and punctuation
    words = [word for word in words if word not in stopwords.words("english") and word.isalpha()]

    # stemming
    words = [stemmer.stem(word) for word in words]

    # join words to make sentence
    document = " ".join(words)

    return document

df['reviews_text'][0]

import nltk
nltk.download('punkt_tab')

preprocess(df['reviews_text'][0])

# Commented out IPython magic to ensure Python compatibility.
# %%time
# df['reviews_clean'] = df['reviews_text'].apply(lambda x: preprocess(x))

joblib.dump(df, 'cleaned_df.gz')

df.head(2)

"""---

#### Visualize top words using word cloud
"""

wordcloud = WordCloud(max_words=200).generate(str(df.reviews_clean))
plt.figure(figsize=(10,10))
plt.imshow(wordcloud)
plt.axis('off')
plt.show()

"""#### Visualize number of words"""

df.reviews_clean.str.len().plot(kind='hist', bins=20)
plt.show()

df.reviews_clean.str.len().plot()
plt.show()

df_reviews_list = df.reviews_clean.str.split()

df_reviews_word_count = df_reviews_list.apply(len)

df_reviews_word_count.value_counts()[0:20].plot(kind='bar')
plt.show()

"""### Observation
Generally reviews seem to have very few relevant words (if we remove stopwords and punctuations)
"""

all_words = ' '.join(df.reviews_clean).split()

from collections import Counter

Counter(all_words).most_common(10)

top_10_words = dict(Counter(all_words).most_common(10))

top_10_words

keys = list(top_10_words)
values = list(top_10_words.values())

sns.barplot(x=keys, y=values)

def extract_ngrams(data, num):
    n_grams = ngrams(nltk.word_tokenize(data), num)
    return [ ' '.join(grams) for grams in n_grams]

Counter(extract_ngrams(' '.join(all_words), 2)).most_common(10)

Counter(extract_ngrams(' '.join(all_words), 3)).most_common(10)

Counter(extract_ngrams(' '.join(all_words), 3)).most_common(10)

Counter(extract_ngrams(' '.join(all_words), 3)).most_common()[20:30]

"""---

## Feature Extraction
- We will be using TF-IDF vectorizer
- Reason is lots of products have common words like "use" or "clorox" which means that we need something that is able to distinguish documents based on how many unique words it contains. TF-IDF is one search metric as it uses "Inverse Document Frequency" during calculation.
"""

vectorizer = TfidfVectorizer(max_features=750, max_df=0.8, min_df=0.01, ngram_range=(1,3))
tfidf_model = vectorizer.fit_transform(df.reviews_clean)

# vectorizer.get_feature_names_out()

pd.DataFrame(tfidf_model.toarray(), columns = vectorizer.get_feature_names_out())

"""### Changing sentiment to binary for training classification model"""

df.user_sentiment = df.user_sentiment.map({'Positive': 1, 'Negative': 0})

df.head(5)

sentiment_labels = df.user_sentiment

df.user_sentiment.value_counts(normalize=True)

"""### Observation

- Very high class imbalance
- Must use SMOTE to fix

## Train Test Split
"""

X_train, X_test, y_train, y_test = train_test_split(tfidf_model, sentiment_labels, random_state=42, test_size=0.20)

counter = Counter(y_train)
print('Before SMOTE', counter)

sm = SMOTE()

# transform the dataset
X_train, y_train = sm.fit_resample(X_train, y_train)

counter = Counter(y_train)
print('After SMOTE',counter)

class ModelBuilder:
    """Custom class to build models and evaluate scores quickly"""
    def __init__(self, model, x_train, x_test, y_train, y_test):
        self.model = model
        self.x_train = x_train
        self.x_test = x_test
        self.y_train = y_train
        self.y_test = y_test


    def train_model(self):
        self.model.fit(self.x_train,self.y_train)
        return self.model.predict(self.x_test)

    def evaluate_model(self, y_pred_class):
        print("\n")
        print("=+"*15)
        self.result_metrics = self.evaluate_metrics(y_pred_class)
        print("=+"*15)
        print("\n")

        self.classification_report(y_pred_class)
        print("\n\n")
        print("=+="*15)
        print("\n")
        self.confusion_matrix(y_pred_class)

        print("=+="*15)
        print("\n")

        metrics.RocCurveDisplay.from_estimator(self.model, self.x_test, self.y_test).plot()

        return self.result_metrics

    def evaluate_metrics(self, y_pred_class):
        """
        - Accuracy
        - Precision
        - Recall
        - F1 Score
        - AUC Value
        """
        result_metrics = []
        accuracy = metrics.accuracy_score(self.y_test, y_pred_class)
        precision = metrics.precision_score(self.y_test, y_pred_class)
        recall = metrics.recall_score(self.y_test, y_pred_class)
        f1score = metrics.f1_score(self.y_test, y_pred_class)
        y_pred_prob = self.model.predict_proba(self.x_test)[:,1]
        roc_auc = metrics.roc_auc_score(self.y_test, y_pred_prob)

        print(f"Accuracy is : {accuracy*100:.1f}%")
        print(f"Precision is : {precision*100:.1f}%")
        print(f"Recall is : {recall*100:.1f}%")
        print(f"F1 Score is : {f1score*100:.1f}%")
        print(f"Roc-Auc Score is:{roc_auc*100:.1f}%")

        result_metrics.append(accuracy)
        result_metrics.append(precision)
        result_metrics.append(recall)
        result_metrics.append(f1score)
        result_metrics.append(roc_auc)
        return result_metrics

    def confusion_matrix(self, y_pred_class):
        confusion_matrix = metrics.confusion_matrix(self.y_test, y_pred_class)
        self.plot_confusion_matrix(confusion_matrix,[0,1])


    def plot_confusion_matrix(self, data, labels):
        sns.set(color_codes=True)
        plt.title("Confusion Matrix")
        ax = sns.heatmap(data/np.sum(data), annot=True, cmap="Reds", fmt=".2%")

        ax.set_xticklabels(labels)
        ax.set_yticklabels(labels)

        ax.set(ylabel="True Values", xlabel="Predicted Values")
        plt.show()

    def classification_report(self, y_pred_class):
        print(metrics.classification_report(self.y_test, y_pred_class))

"""---

## Naive Bayes
"""

# training the NB model and making predictions
mnb = MultinomialNB()
mnb_modebuilder = ModelBuilder(mnb, X_train, X_test, y_train, y_test)
# Train and Predict the Test Labels
y_pred_class  = mnb_modebuilder.train_model()
nb_metrics = mnb_modebuilder.evaluate_model(y_pred_class)

thresholds = np.round(np.arange(0, 1, 0.1), 2)
threshold_df = generate_prob_threshold_df(y_train, mnb.predict_proba(X_train), thresholds)

cutoff_df = generate_optimal_cutoff_df(threshold_df, thresholds)
# cutoff_df.head()

# Let's plot accuracy sensitivity and specificity for various probabilities.
cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])
plt.show()

metrics_on_different_thresholds(y_train, thresholds, threshold_df)

"""#### Decision
0.5 seems to be optimal cut-off point
"""

classification_metrics(y_train, threshold_df[0.5], 'naive_bayes_train')

threshold_df_test = generate_prob_threshold_df(y_test, mnb.predict_proba(X_test), thresholds)
classification_metrics(y_test, threshold_df_test[0.5], 'naive_bayes_test')

"""---

Among all the options, the train score was highest with xgboost, however, the test score is poor which signals at overfitting especially looking at FPR.

After carefully studying the options, it seems `naive bayes` model might be the best as even though it is has low scores in some metrics, overall it is perfoming okay and test/train scores are similar indicating that the model is actually learning something as opposed to mugging up training data.

### Decision
Picking `Naive Bayes` based model
"""

joblib.dump(mnb, 'mnb.pkl')

"""---

## Recommendation System
- User based Collaborative Filtering
- Item based Collaborative Filtering

### Divide data in train and test
"""

train, test = train_test_split(df, test_size=0.30, random_state=31)

train.shape, test.shape

"""## User Based"""

# Pivot the train ratings' dataset into matrix format in which columns are movies and the rows are user IDs.
df_pivot = train.pivot_table(
    index='reviews_username',
    columns='name',
    values='reviews_rating',
    # aggfunc='mean'
).fillna(0)

df_pivot.head(3)

"""#### Creating dummy train and test dataset
- Dummy Train will be used for prediction
    - To ignore products rated by the user we will mark it as 0 during prediction
    - products not rated by the user will be marked as 1
- Dummy Test will be used for evaluation
    - To evaluate, we will only make prediction on products rated by user
    - The 0/1 marking will be opposite to the train set
"""

dummy_train = train.copy()
dummy_train['reviews_rating'] = dummy_train['reviews_rating'].apply(lambda x: 0 if x>=1 else 1)

# Convert the dummy train dataset into matrix format.
dummy_train = dummy_train.pivot_table(
    index='reviews_username',
    columns='name',
    values='reviews_rating'
).fillna(1)

dummy_train.head()

"""#### Cosine Similarity
- This is used to measure similarity between two vectors

#### Adjusted Cosine
- Adjusted cosine similarity is a modified version of vector-based similarity where we incorporate the fact that different users have different ratings schemes.
    - some users might rate items highly in general, and
    - others might give items lower ratings as a preference.
- To handle this nature from rating given by user, we subtract average ratings for each user from each user's rating for different products.
"""

# Here, we are not removing the NaN values and
# calculating the mean only for the products rated by the user
df_pivot = train.pivot_table(
    index='reviews_username',
    columns='name',
    values='reviews_rating'
)

mean = np.nanmean(df_pivot, axis=1)
df_subtracted = (df_pivot.T-mean).T

# df_subtracted.head()

# Creating the User Similarity Matrix using pairwise_distance function.
user_correlation = 1 - pairwise_distances(df_subtracted.fillna(0), metric='cosine')
user_correlation[np.isnan(user_correlation)] = 0
print(user_correlation)

user_correlation.shape

"""#### Prediction - User User
Doing the prediction for the users which are positively related with other users, and not the users which are negatively related as we are interested in the users which are more similar to the current users. So, ignoring the correlation for values less than 0.
"""

user_correlation[user_correlation<0]=0
user_correlation

"""Rating predicted by the user (for products rated as well as not rated) is the weighted sum of correlation with the product rating (as present in the dataset)."""

user_predicted_ratings = np.dot(user_correlation, df_pivot.fillna(0))
user_predicted_ratings

user_predicted_ratings.shape

"""Since we are interested only in the products not rated by the user, we will ignore the products rated by the user by making it zero."""

user_final_rating = np.multiply(user_predicted_ratings,dummy_train)
user_final_rating.head()

"""### Finding the top 5 recommendation for the *user*"""

user_inp = '00sab00'

d = user_final_rating.loc[user_inp].sort_values(ascending=False)[0:5]
d

"""### Evaluation - User User
- Here we will consider products already rated by the user
"""

# Find out the common users of test and train dataset.
common = test[test.reviews_username.isin(train.reviews_username)]
common.shape

common.head(2)

# convert into the user-product matrix.
common_user_based_matrix = common.pivot_table(index='reviews_username', columns='name', values='reviews_rating')

# Convert the user_correlation matrix into dataframe.
user_correlation_df = pd.DataFrame(user_correlation)

df_subtracted.head(1)

user_correlation_df['reviews_username'] = df_subtracted.index
user_correlation_df.set_index('reviews_username',inplace=True)
user_correlation_df.head()

list_name = common.reviews_username.tolist()
user_correlation_df.columns = df_subtracted.index.tolist()
user_correlation_df_1 =  user_correlation_df[user_correlation_df.index.isin(list_name)]

user_correlation_df_1.shape

user_correlation_df_2 = user_correlation_df_1.T[user_correlation_df_1.T.index.isin(list_name)]
user_correlation_df_3 = user_correlation_df_2.T
user_correlation_df_3.head()

user_correlation_df_3.shape

user_correlation_df_3[user_correlation_df_3<0]=0

common_user_predicted_ratings = np.dot(user_correlation_df_3, common_user_based_matrix.fillna(0))
common_user_predicted_ratings

dummy_test = common.copy()
dummy_test['reviews_rating'] = dummy_test['reviews_rating'].apply(lambda x: 1 if x>=1 else 0)
dummy_test = dummy_test.pivot_table(index='reviews_username', columns='name', values='reviews_rating').fillna(0)

dummy_test.shape

common_user_predicted_ratings = np.multiply(common_user_predicted_ratings,dummy_test)
common_user_predicted_ratings.head(2)

"""Calculating the RMSE for only the products rated by user. For RMSE, normalising the rating to (1,5) range."""

X  = common_user_predicted_ratings.copy()
X = X[X>0]

scaler = MinMaxScaler(feature_range=(1, 5))
print(scaler.fit(X))
y = (scaler.transform(X))

print(y)

common_ = common.pivot_table(index='reviews_username',
                             columns='name',
                             values='reviews_rating')

total_non_nan = np.count_nonzero(~np.isnan(y))

common_.head(1)

"""#### RMSE - User User"""

((((common_ - y)**2).sum().sum())/total_non_nan)**0.5

"""---

### Filtering the rating only for the products not rated by the user for recommendation
"""

item_final_rating = np.multiply(item_predicted_ratings,dummy_train)
item_final_rating.head()

"""### Finding the top 5 recommendation for the *user*"""

user_inp = '00sab00'

# Recommending the Top 5 products to the user.
d = item_final_rating.loc[user_inp].sort_values(ascending=False)[0:5]
d

"""### Observation
- the RMSE value for `user based recommendation engine` is better
- Additionally, looking at the `user_final_rating` and `item_final_rating` outputs for some users makes it seem that `user based` system will have more (correct) matching results for this database.

### Decision
#### Choosing `user based collaborative filtering` for Recommendation Engine

---

## Recommend top 20 products for selected user
"""

user_final_rating.head(1)

user_inp = input('Enter username to get top 20 recommendations:')

user_final_rating.loc[user_inp].sort_values(ascending=False)[0:20]

joblib.dump(user_final_rating, 'user_based_recommendation.gz')

"""---

## Positive Sentiment Percentage for Recommended Products
"""

product_names = user_final_rating.loc[user_inp].sort_values(ascending=False)[0:20].index.to_list()

product_names[0:5]

df[(df['name'] == product_names[0]) & (df['user_sentiment'] == 1)].shape[0]/df[df['name'] == product_names[0]].shape[0]

pos_df = pd.DataFrame(columns=['name', 'positive %'])
for product_name in product_names:
    positive_percentage = df[(df['name'] == product_name) & (df['user_sentiment'] == 1)].shape[0]/df[df['name'] == product_name].shape[0]
    pos_df.loc[len(pos_df.index)] = [product_name, positive_percentage]

pos_df.sort_values(by='positive %', ascending=False).reset_index().drop('index', axis=1)

def get_sentiment_recommendations(user):
    """
    - Predict the sentiment of all the reviews for a product using classifier
    - Group the information over product name
    - Extract total positive ratio to sort the products from most popular to least popular.
    """
    if (user in user_final_rating.index):
        # get the product recommedation using the trained ML model
        recommendations = list(user_final_rating.loc[user].sort_values(ascending=False)[0:20].index)
        temp = train[train.name.isin(recommendations)].copy()
        X = vectorizer.transform(temp["reviews_clean"].values.astype(str))
        temp["predicted_sentiment"] = mnb.predict(X)
        temp = temp[['name', 'predicted_sentiment']]
        temp_grouped = temp.groupby('name', as_index=False).count()
        temp_grouped["pos_review_count"] = temp_grouped.name.apply(lambda x: temp[(temp.name==x) & (temp.predicted_sentiment==1)]["predicted_sentiment"].count())
        temp_grouped["total_review_count"] = temp_grouped['predicted_sentiment']
        temp_grouped['pos_sentiment_percent'] = np.round(temp_grouped["pos_review_count"]/temp_grouped["total_review_count"]*100,2)
        temp_grouped.drop('predicted_sentiment', axis=1, inplace=True)
        return temp_grouped.sort_values('pos_sentiment_percent', ascending=False)
    else:
        print(f"User name {user} doesn't exist")

get_sentiment_recommendations("08dallas")

"""---

## Filter Top 5
"""

get_sentiment_recommendations("08dallas")[:5]

get_sentiment_recommendations("00sab00")[:5]

"""---

### Validating Negative Case (User does not exist)
"""

get_sentiment_recommendations("does-not-exist")[:5]

"""### Validating Sentiment Classification"""

X_sample = vectorizer.transform(["Awesome product, will recommend"])
y_pred_sample = mnb.predict(X_sample)
y_pred_sample

X_sample = vectorizer.transform(["worst product, quality is poor"])
y_pred_sample = mnb.predict(X_sample)
y_pred_sample

"""---

## Model Deployment Files

Storing
- User based Recommendation Model
- Sentiment Classification Model
- Train Dataset (used in recommendation model)
- Vectorizer

As these will be required for deployment.
"""

joblib.dump(mnb, 'mnb.gz') # sentiment classifier
joblib.dump(user_final_rating, 'user_final_rating.gz') # recommendation engine
joblib.dump(train, 'dataset.gz') # dataset with cleaned reviews used for filtering top 5 results
joblib.dump(vectorizer, 'vectorizer.gz') # tf-idf vectorizer

"""---

### Preparing function to get top 5 products
- name
- brand
- manufacture
- positive sentiment %
"""

def get_sentiment_recommendations(user):
    """
    - Predict the sentiment of all the reviews for a product using classifier
    - Group the information over product name
    - Extract total positive ratio to sort the products from most popular to least popular.
    """
    if (user in user_final_rating.index):
        # get the product recommedation using the trained ML model
        recommendations = list(user_final_rating.loc[user].sort_values(ascending=False)[0:20].index)
        temp = train[train.name.isin(recommendations)].copy()
        X = vectorizer.transform(temp["reviews_clean"].values.astype(str))
        temp["predicted_sentiment"] = mnb.predict(X)
        temp = temp[['name', 'predicted_sentiment']]
        temp_grouped = temp.groupby('name', as_index=False).count()
        temp_grouped["pos_review_count"] = temp_grouped.name.apply(lambda x: temp[(temp.name==x) & (temp.predicted_sentiment==1)]["predicted_sentiment"].count())
        temp_grouped["total_review_count"] = temp_grouped['predicted_sentiment']
        temp_grouped['pos_sentiment_percent'] = np.round(temp_grouped["pos_review_count"]/temp_grouped["total_review_count"]*100,2)
        temp_grouped.drop('predicted_sentiment', axis=1, inplace=True)
        sorted_top_5 = temp_grouped.sort_values('pos_sentiment_percent', ascending=False)[0:5]
        top_5_products = pd.merge(
            train[['name', 'brand', 'manufacturer']].drop_duplicates(),
            sorted_top_5[['name', 'pos_sentiment_percent']], on='name'
        ).sort_values('pos_sentiment_percent', ascending=False).rename(
            columns={
                'pos_sentiment_percent': 'Positive Sentiment %',
                'name': 'Name',
                'brand': 'Brand',
                'manufacturer': 'Manufacturer'
            }
        ).reset_index(drop=True)
        top_5_products.index = np.arange(1, len(top_5_products)+1)
        top_5_products.columns.name = 'S. No.'
        return top_5_products
    else:
        print(f"User name {user} doesn't exist")

get_sentiment_recommendations("00sab00")

"""
Preparing Function to return HTML response for Flask App"""

df_html = get_sentiment_recommendations("00sab00").to_html().replace(
    'table border="1"', 'table border="1" style="border-collapse:collapse"'
).replace(
    'tr style="text-align: right;"', 'tr style="text-align: center; background-color: beige;"'
).replace(
    '<td>', '<td style="text-align:center; padding: 0.5em;">'
).replace(
    '<th>', '<th style="text-align:center; padding: 0.3em;">'
)

with open('test.html', 'w') as f:
    f.write(df_html)

"""---

---

# References
- https://stackoverflow.com/questions/51070985/find-out-the-percentage-of-missing-values-in-each-column-in-the-given-dataset
- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html
- https://stackoverflow.com/questions/57708107/pandas-to-datetime-function-doesnt-change-dtype
- https://stackoverflow.com/questions/38916452/nltk-download-ssl-certificate-verify-failed
- https://stackoverflow.com/questions/4743035/how-to-get-the-least-common-element-in-a-list
- https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html
- https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/
- https://datascience.stackexchange.com/questions/33730/should-i-rescale-tfidf-features
- https://www.w3schools.com/cssref/pr_border-collapse.asp
- https://stackoverflow.com/questions/18022845/pandas-index-column-title-or-name

---
"""

